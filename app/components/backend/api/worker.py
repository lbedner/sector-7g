
"""Worker task API endpoints."""

from datetime import datetime, timedelta

from fastapi import APIRouter, HTTPException

from app.components.backend.api.models import (
    TaskListResponse,
    TaskRequest,
    TaskResponse,
    TaskResultResponse,
    TaskStatusResponse,
)
from app.components.worker.pools import get_queue_pool
from app.components.worker.tasks import get_task_by_name, list_available_tasks
from app.core.config import get_default_queue
from app.core.log import logger

router = APIRouter(prefix="/tasks", tags=["worker"])


@router.get("/", response_model=TaskListResponse)
async def list_tasks() -> TaskListResponse:
    """Get list of all available background tasks."""
    available_tasks = list_available_tasks()

    from app.components.worker.tasks import get_queue_for_task
    from app.core.config import get_available_queues

    queues: dict[str, list[str]] = {
        queue_type: [] for queue_type in get_available_queues()
    }

    for task in available_tasks:
        queue_type = get_queue_for_task(task)
        queues[queue_type].append(task)

    return TaskListResponse(
        available_tasks=available_tasks,
        total_count=len(available_tasks),
        queues=queues,
    )


@router.post("/enqueue", response_model=TaskResponse)
async def enqueue_task(task_request: TaskRequest) -> TaskResponse:
    """Enqueue a background task for processing."""
    logger.info(
        f"Enqueueing task: {task_request.task_name} (queue: {task_request.queue_type})"
    )

    task_func = get_task_by_name(task_request.task_name)
    if not task_func:
        available_tasks = list_available_tasks()
        raise HTTPException(
            status_code=400,
            detail={
                "error": "invalid_task_name",
                "message": f"Task '{task_request.task_name}' not found",
                "available_tasks": available_tasks,
            },
        )

    from app.core.config import get_available_queues, is_valid_queue

    if not is_valid_queue(task_request.queue_type):
        available_queues = get_available_queues()
        raise HTTPException(
            status_code=400,
            detail={
                "error": "invalid_queue_type",
                "message": f"Queue type must be one of: {available_queues}",
            },
        )

    try:
        pool, queue_name = await get_queue_pool(task_request.queue_type)

        job = await pool.enqueue_job(
            task_request.task_name,
            *task_request.args,
            _queue_name=queue_name,
            _defer_by=task_request.delay_seconds,
            **task_request.task_kwargs,
        )

        queued_at = datetime.now()
        estimated_start = None
        if task_request.delay_seconds:
            estimated_start = queued_at + timedelta(seconds=task_request.delay_seconds)

        await pool.aclose()

        if job is None:
            raise HTTPException(status_code=500, detail="Failed to enqueue task")

        logger.info(f"Task enqueued: {job.job_id} ({task_request.task_name})")

        return TaskResponse(
            task_id=job.job_id,
            task_name=task_request.task_name,
            queue_type=task_request.queue_type,
            queued_at=queued_at,
            estimated_start=estimated_start,
            message=(
                f"Task '{task_request.task_name}' enqueued to "
                f"{task_request.queue_type} queue"
            ),
        )

    except Exception as e:
        logger.error(f"Failed to enqueue task {task_request.task_name}: {e}")
        raise HTTPException(
            status_code=500,
            detail={
                "error": "enqueue_failed",
                "message": f"Failed to enqueue task: {str(e)}",
            },
        )


@router.get("/status/{task_id}", response_model=TaskStatusResponse)
async def get_task_status(task_id: str) -> TaskStatusResponse:
    """Get the status of a background task."""
    try:
        pool, _ = await get_queue_pool(get_default_queue())

        job_key = f"arq:job:{task_id}"
        result_key = f"arq:result:{task_id}"

        job_exists = await pool.exists(job_key)
        result_exists = await pool.exists(result_key)

        if not job_exists and not result_exists:
            await pool.aclose()
            raise HTTPException(
                status_code=404,
                detail={
                    "error": "task_not_found",
                    "message": f"Task {task_id} not found",
                },
            )

        if result_exists:
            result_data = await pool.get(result_key)
            if result_data:
                try:
                    import pickle

                    result = pickle.loads(result_data)
                    if isinstance(result, dict) and result.get("error"):
                        status = "failed"
                        error = result.get("error")
                    else:
                        status = "complete"
                        error = None
                except Exception:
                    status = "complete"
                    error = None
            else:
                status = "complete"
                error = None
        elif job_exists:
            status = "queued"
            error = None
        else:
            status = "unknown"
            error = None

        await pool.aclose()

        return TaskStatusResponse(
            task_id=task_id,
            status=status,
            result_available=result_exists,
            error=error,
            enqueue_time=None,
            start_time=None,
            finish_time=None
        )

    except Exception as e:
        logger.error(f"Failed to get task status for {task_id}: {e}")
        raise HTTPException(
            status_code=500, detail={"error": "status_check_failed", "message": str(e)}
        )


@router.get("/result/{task_id}", response_model=TaskResultResponse)
async def get_task_result(task_id: str) -> TaskResultResponse:
    """Get the result of a completed background task."""
    try:
        pool, _ = await get_queue_pool(get_default_queue())

        result_key = f"arq:result:{task_id}"
        result_exists = await pool.exists(result_key)

        if not result_exists:
            job_key = f"arq:job:{task_id}"
            job_exists = await pool.exists(job_key)
            await pool.aclose()

            if not job_exists:
                raise HTTPException(
                    status_code=404,
                    detail={
                        "error": "task_not_found",
                        "message": f"Task {task_id} not found",
                    },
                )
            else:
                raise HTTPException(
                    status_code=400,
                    detail={
                        "error": "task_not_completed",
                        "message": f"Task {task_id} has not completed yet",
                        "current_status": "queued or in_progress",
                    },
                )

        result_data = await pool.get(result_key)
        await pool.aclose()

        if not result_data:
            raise HTTPException(
                status_code=500,
                detail={
                    "error": "result_data_missing",
                    "message": "Result data is missing",
                },
            )

        try:
            import pickle

            result = pickle.loads(result_data)

            if isinstance(result, Exception):
                result_data = {
                    "error_type": type(result).__name__,
                    "error_message": str(result),
                    "task_failed": True,
                }
                task_status = "failed"
            else:
                try:
                    import json

                    json.dumps(result)
                    result_data = result
                    task_status = "completed"
                except (TypeError, ValueError):
                    result_data = {
                        "result_type": type(result).__name__,
                        "result_str": str(result),
                        "note": "Result was not JSON-serializable, converted to string",
                    }
                    task_status = "completed"

            return TaskResultResponse(
                task_id=task_id,
                status=task_status,
                result=result_data,
                enqueue_time=None,
                start_time=None,
                finish_time=None
            )

        except Exception as e:
            raise HTTPException(
                status_code=500,
                detail={
                    "error": "result_deserialization_failed",
                    "message": f"Failed to deserialize result: {str(e)}",
                },
            )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get task result for {task_id}: {e}")
        raise HTTPException(
            status_code=500, detail={"error": "result_fetch_failed", "message": str(e)}
        )
